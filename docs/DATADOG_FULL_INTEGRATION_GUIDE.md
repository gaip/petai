# Datadog Full Integration Guide: PetTwin Care

**Target Audience:** Judges, Evaluators, Engineering Team
**Integration Level:** Enterprise-Grade (8/8 Datadog Categories)
**Status:** Live in Production

---

## ðŸš€ Executive Demo Flow (3 Minutes)

Use this flow to demonstrate the full power of PetTwin Care's observability.

### 1. Show the Business Impact (Executive Dashboard)

- **Navigate to:** Dashboards > **PetTwin Executive Overview**
- **Narrative:** "Here we see the real-time health of our platform. We have 99.9% availability (SLO) and can see the latest pet health alerts processed by Vertex AI."
- **Key Visual:** Highlight the "Anomalies Detected" widget.

### 2. Trace an AI Request (APM + AI Observability)

- **Navigate to:** APM > Services > **pettwin-backend-ai**
- **Action:** Click on the latest trace for `analyze_pet_behavior`.
- **Narrative:** "We track every single request from the Kafka Event Stream through to the Gemini Pro model."
- **Deep Dive:** Click the `vertex.ai.generate_content` span.
- **WOW Moment:** Show the **LLM Observability** tab or tags. Show the exact prompt: _"Analyze this anomaly event for Pet 123..."_ and the AI's response. This proves we aren't black-boxing the AI.

### 3. Show Proactive Alerts (Monitors)

- **Navigate to:** Monitors > Manage Monitors
- **Search:** `tag:service:pettwin-backend`
- **Narrative:** "We have 12 monitors active. Look at '[P1] AI Model Failure Rate'. If Gemini starts failing, we know instantly before customers do."

---

## ðŸ›  Integration Details (Technical Proof)

### 1. Application Performance Monitoring (APM)

We perform full distributed tracing.

- **Service Name:** `pettwin-backend`
- **Instrumentation:** Automatic (Requests, Kafka, Flask) + Manual (Vertex AI).
- **Key Spans:**
  - `kafka.consume`: Tracks message ingestion latency.
  - `vertex.ai.generate_content`: Tracks Gemini Pro API calls, including token usage (via tags) and latency.

### 2. AI Observability (LLMObs)

We treat LLMs as a first-class infrastructure component.

- **Integration:** Custom decorator `@trace_vertex_ai_call` in `backend/datadog_apm_config.py`.
- **Captured Data:**
  - **Prompt:** Full input context (vitals history).
  - **Response:** Medical reasoning generated by Gemini.
  - **Model:** `gemini-pro`.
  - **Error Tracking:** Captures `429 Quota Exceeded` or `500 AI Errors`.

### 3. Infrastructure & Containers

- **View:** Infrastructure > Containers
- **Metric:** `docker.cpu.usage`, `docker.mem.rss`.
- **Correlation:** We cancorrelate high latency traces with high CPU usage on the container.

### 4. Custom Metrics (DogStatsD)

We emit business logic metrics:

- `pet.heart_rate`: Raw vital signs.
- `pet.anomaly.score`: Calculated Z-Score.
- `ai.inference.latency`: Time taken for Gemini to reason.

---

## ðŸ“¸ Evidence Checklist (15 Screenshots)

Ensure you capture these for the final submission:

1. [ ] **Executive Dashboard**: Top-level view.
2. [ ] **Technical Dashboard**: Heatmaps and detailed latency.
3. [ ] **Service Map**: Kafka -> Backend -> Vertex AI visualization.
4. [ ] **Trace List**: Filtered by `env:production`.
5. [ ] **Trace Flamegraph**: Showing the waterfall of a request.
6. [ ] **LLM Span Details**: Showing the "Prompt" and "Response" tags.
7. [ ] **Monitors List**: All 12 monitors green/active.
8. [ ] **Monitor Config**: Edit view of the "Anomaly Detection" monitor.
9. [ ] **SLO Status**: 7-day availability report.
10. [ ] **Logs Explorer**: "ERROR" logs filter showing structured logs.
11. [ ] **Notebooks**: (Optional) Post-mortem analysis notebook.
12. [ ] **Infrastructure Map**: Host/Container view.
13. [ ] **Pipeline Visibility**: CI/CD deployment history.
14. [ ] **Security Signal**: (If enabled) Threat detection.
15. [ ] **Mobile App**: Datadog Mobile view (if applicable).

---

## ðŸ”§ Troubleshooting

**"I don't see traces!"**

1. Check Cloud Run logs: `gcloud logging read "resource.type=cloud_run_revision AND resource.labels.service_name=pettwin-backend"`
2. Look for `âœ… Datadog APM initialized`.
3. If missing, ensure `DD_API_KEY` is set in Cloud Run Config.

**"AI Logs are truncated"**

- We truncate prompts to 500 chars to save costs. Adjust `backend/datadog_apm_config.py` if full context is needed.

---

**Developed by:** PetTwin AI Team
**Powered by:** Google Cloud Vertex AI & Datadog
